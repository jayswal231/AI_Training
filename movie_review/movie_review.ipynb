{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfaab626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "# https://drive.google.com/file/d/192jeGRTCZZfet8ufHPfaMn05T7Biklfw/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46b287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1a3e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 22:59:29.448609: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-15 22:59:29.473081: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-15 22:59:29.473220: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mukesh-Inspiron-5468): /proc/driver/nvidia/version does not exist\n",
      "2022-11-15 22:59:29.629661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "\n",
    "# Assumes you're in the root level of the dataset directory.\n",
    "# If you aren't, you'll need to change the relative paths here.\n",
    "train_data = text_dataset_from_directory(\"movie-reviews-dataset/movie-reviews-dataset/test\")\n",
    "test_data = text_dataset_from_directory(\"movie-reviews-dataset/movie-reviews-dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2e2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "from tensorflow.strings import regex_replace\n",
    "\n",
    "def prepareData(dir):\n",
    "  data = text_dataset_from_directory(dir)\n",
    "  return data.map(\n",
    "    lambda text, label: (regex_replace(text, '<br />', ' '), label),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21a78c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = prepareData(\"movie-reviews-dataset/movie-reviews-dataset/test\")\n",
    "test_data = prepareData(\"movie-reviews-dataset/movie-reviews-dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54add890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Symbolism galore, great tunes, this film crushed their \"soon to be no more\" target audience\\'s expectations. These monkees and the naturally selected members of the group, were witnessing a subtle yet in your face, kiss goodbye to each other. The message rings true today, the cage you escape from and the bridge you want to jump off of, are the next generations own disappointments, there will always be new kids on the block replacing those who break free from the chains. The film can be frustrating at times, because the themes the film attacks are so blatantly apart of the American way of life, a thinking and reasoning person cannot help but stare at their own reflection in the scenes of Head, and question not only their personal motives for continuing the madness of everyday American life, but the motives of those who want it to continue for the sake of madness. The final scene, similar to Don Quixote\\'s chivalric daring of the caged tiger to exit for battle, represents just how delusional and impossible most dreams are.'\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_data.take(1):\n",
    "    print(text_batch.numpy()[0])\n",
    "    print(label_batch.numpy()[0]) # 0 = negative, 1 = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bedf71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(1,), dtype=\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead117d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "max_tokens = 1000\n",
    "max_len = 100\n",
    "vectorize_layer = TextVectorization(\n",
    "  # Max vocab size. Any words outside of the max_tokens most common ones\n",
    "  # will be treated the same way: as \"out of vocabulary\" (OOV) tokens.\n",
    "  max_tokens=max_tokens,\n",
    "  # Output integer indices, one per string token\n",
    "  output_mode=\"int\",\n",
    "  # Always pad or truncate to exactly this many tokens\n",
    "  output_sequence_length=max_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d78d5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call adapt(), which fits the TextVectorization layer to our text dataset.\n",
    "# This is when the max_tokens most common words (i.e. the vocabulary) are selected.\n",
    "train_texts = train_data.map(lambda text, label: text)\n",
    "vectorize_layer.adapt(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "532ddcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(vectorize_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "061ffe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "model.add(Embedding(max_tokens + 1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5420e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "model.add(LSTM(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd3c63f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 100)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 128)          128128    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 64, 128)           128128    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 359,297\n",
      "Trainable params: 359,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Embedding(max_tokens + 1, 128))\n",
    "\n",
    "# ----- 4. RECURRENT LAYER\n",
    "model.add(LSTM(64))\n",
    "\n",
    "# ----- 5. DENSE HIDDEN LAYER\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "# ----- 6. OUTPUT\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd64ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import SimpleRNN\n",
    "# # build model\n",
    "# model.add(SimpleRNN(128, return_sequences=True))\n",
    "# # model.add(SimpleRNN(128, return_sequences=True))\n",
    "# model.add(SimpleRNN(128, return_sequences=False))\n",
    "# model.add(Dense(20))\n",
    "# model.add(Dense(64, activation=\"relu\"))\n",
    "# model.add(Dense(1, activation=\"sigmoid\"))\n",
    "# model.build()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9be2d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "663cb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ab9e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c760c269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'lstm/lstm_cell/kernel:0', 'lstm/lstm_cell/recurrent_kernel:0', 'lstm/lstm_cell/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'lstm/lstm_cell/kernel:0', 'lstm/lstm_cell/recurrent_kernel:0', 'lstm/lstm_cell/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "782/782 [==============================] - 41s 46ms/step - loss: 0.6935 - accuracy: 0.5025\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 38s 48ms/step - loss: 0.6933 - accuracy: 0.4987\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 38s 48ms/step - loss: 0.6933 - accuracy: 0.4998\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 36s 46ms/step - loss: 0.6933 - accuracy: 0.4990\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 36s 46ms/step - loss: 0.6933 - accuracy: 0.4996\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 0.6932 - accuracy: 0.4982\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 38s 48ms/step - loss: 0.6932 - accuracy: 0.5010\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.6932 - accuracy: 0.4984\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 36s 46ms/step - loss: 0.6932 - accuracy: 0.4995\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 36s 45ms/step - loss: 0.6933 - accuracy: 0.5012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f919063ce20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "698ae97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: movie-reviews-dataset/movie-reviews-dataset/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: movie-reviews-dataset/movie-reviews-dataset/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('movie-reviews-dataset/movie-reviews-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4b9afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('movie-reviews-dataset/movie-reviews-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7798b38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "[[0.50448453]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "[[0.50448453]]\n"
     ]
    }
   ],
   "source": [
    "# Should print a very high score like 0.98.\n",
    "print(model.predict([\n",
    "  \"i loved it! highly recommend it to anyone and everyone looking for a great movie to watch.\",\n",
    "]))\n",
    "\n",
    "# Should print a very low score like 0.01.\n",
    "print(model.predict([\n",
    "  \"this was awful! i hated it so much, nobody should watch this. the acting was terrible, the music was terrible, overall it was just bad.\",\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c7a673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
